{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "basepath = '/content/drive/MyDrive/research/Infinite/'\n",
    "\n",
    "import sys\n",
    "sys.path.append('/content/drive/MyDrive/research/Infinite/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install pytorch-lightning\n",
    "! pip install transformers\n",
    "! pip install seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "basepath = './'\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import seed_everything, loggers as pl_loggers\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from transformers import  DistilBertModel,DistilBertTokenizerFast\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from scripts.dataset import *\n",
    "from scripts.model import IC_NER\n",
    "from scripts.utils import *\n",
    "from arguments import jointBert_argument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameter\n",
    "config = {\n",
    "\n",
    "'mc' : {\n",
    "    'model_name' : 'distilbert-base-multilingual-cased',\n",
    "    'tokenizer_name' : 'distilbert-base-multilingual-cased',\n",
    "    'joint_loss_coef' : 0.5,\n",
    "    'id_1': 0.3742511688366331,\n",
    "    'id_2':0.4907499594086448,\n",
    "    'sd':0.4103913444544801,\n",
    "    'Ihs': 90\n",
    "},\n",
    "\n",
    "# training parameters\n",
    "'tc' : {\n",
    "    'lr' : 0.00003,\n",
    "    'epoch' : 20,\n",
    "    'batch_size' : 16,\n",
    "    'weight_decay' : 0.003,\n",
    "    'shuffle_data' : True,\n",
    "    'num_worker' : 8\n",
    "},\n",
    "\n",
    "# data params\n",
    "\n",
    "'dc' : {\n",
    "    'train_dir' : basepath + 'data/multiATIS/split/train/clean/train.tsv',\n",
    "    'val_dir' : basepath + 'data/multiATIS/split/valid/clean/val.tsv',\n",
    "    'intent_num' : 18,\n",
    "    'slots_num' : 159,\n",
    "    'max_len' : 56\n",
    "},\n",
    "\n",
    "# misc\n",
    "'misc' : {\n",
    "    'fix_seed' : False,\n",
    "    'gpus' : -1,\n",
    "    'log_dir' : './',\n",
    "    'precision' : 16,\n",
    "}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading slot index file\n",
    "final_slots = pd.read_csv( basepath + 'data/multiATIS/slots_list.csv',sep=',',header=None,names=['SLOTS']).SLOTS.values.tolist()\n",
    "idx2slots  = {idx:slots for idx,slots in enumerate(final_slots)}\n",
    "\n",
    "# callback for pytorch lightning\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_IC_NER_loss',\n",
    "    dirpath= basepath + 'bin/clean/',\n",
    "    filename='jointBert-{epoch:02d}-{val_loss:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='min',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class jointBert(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.IC_NER = IC_NER(cfg)\n",
    "        self.cfg = cfg\n",
    "\n",
    "    def forward(self, input_ids, attention_mask , intent_target, slots_target):\n",
    "        return self.IC_NER(input_ids, attention_mask , intent_target, slots_target)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \n",
    "        token_ids, attention_mask = batch['token_ids'], batch['mask']\n",
    "        intent_target,slots_target = batch['intent_id'], batch['slots_id']\n",
    "        \n",
    "        out = self(token_ids,attention_mask,intent_target,slots_target)\n",
    "        \n",
    "        self.log('train_IC_NER_loss', out['joint_loss'], on_step=False, on_epoch=True, logger=True)\n",
    "        self.log('train_IC_loss', out['ic_loss'], on_step=False, on_epoch=True, logger=True)\n",
    "        self.log('train_NER_loss', out['ner_loss'], on_step=False, on_epoch=True, logger=True)\n",
    "        \n",
    "        return out['joint_loss']\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \n",
    "        token_ids, attention_mask = batch['token_ids'], batch['mask']\n",
    "        intent_target,slots_target = batch['intent_id'], batch['slots_id']\n",
    "        \n",
    "        out = self(token_ids,attention_mask,intent_target,slots_target)\n",
    "        intent_pred, slot_pred = out['intent_pred'], out['slot_pred']\n",
    "        \n",
    "        self.log('val_IC_NER_loss', out['joint_loss'], on_step=False, on_epoch=True,  logger=True)\n",
    "        self.log('val_IC_loss', out['ic_loss'], on_step=False, on_epoch=True,  logger=True)\n",
    "        self.log('val_NER_loss', out['ner_loss'], on_step=False, on_epoch=True,  logger=True)\n",
    "        self.log('val_intent_acc', accuracy(out['intent_pred'],intent_target), on_step=False, on_epoch=True,  logger=True)\n",
    "        self.log('slot_f1', slot_F1(out['slot_pred'],slots_target,idx2slots), on_step=False, on_epoch=True, logger=True)\n",
    "        \n",
    "        \n",
    "        return out['joint_loss']\n",
    "    \n",
    "    def test_step(self,batch,batch_idx):\n",
    "        \n",
    "        token_ids, attention_mask = batch['token_ids'], batch['mask']\n",
    "        intent_target,slots_target = batch['intent_id'], batch['slots_id']\n",
    "        \n",
    "        out = self(token_ids,attention_mask,intent_target,slots_target)\n",
    "        intent_pred, slot_pred = out['intent_pred'], out['slot_pred']\n",
    "        \n",
    "        self.log('test_intent_acc', accuracy(intent_pred,intent_target), on_step=False, on_epoch=True,  logger=True)\n",
    "        self.log('test_slot_f1', slot_F1(slot_pred,slots_target,idx2slots), on_step=False, on_epoch=True, logger=True)\n",
    "        \n",
    "        return out['joint_loss']\n",
    "        \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "         return torch.optim.AdamW( self.parameters(), lr=config['tc']['lr'] ,  weight_decay=self.cfg['tc']['weight_decay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the dataloader\n",
    "dm = NLU_Dataset_pl(config['dc']['train_dir'], config['dc']['val_dir'], config['dc']['val_dir'],\n",
    "                   config['mc']['tokenizer_name'], config['dc']['max_len'], config['tc']['batch_size'],\n",
    "                    config['tc']['num_worker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the model\n",
    "model = jointBert(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "Using native 16bit precision.\n"
     ]
    }
   ],
   "source": [
    "# model training\n",
    "trainer = pl.Trainer(gpus=config['misc']['gpus'],callbacks=[checkpoint_callback] ,accumulate_grad_batches=4,precision=config['misc']['precision'],max_epochs=config['tc']['epoch'], check_val_every_n_epoch=1)\n",
    "\n",
    "#trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_mean_stderror(metric):\n",
    "    \n",
    "    if len(metric) == 1:\n",
    "        return metric\n",
    "    var,std_error = 0,0\n",
    "    mean = sum(metric)/len(metric)\n",
    "    for m in metric:\n",
    "        var += (m-mean)**2\n",
    "    var = (var/(len(metric)-1))**0.5\n",
    "    std_error = var/((len(metric))**0.5)\n",
    "    return [round(mean,4),round(std_error,4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd888e4eff914b3d8e54cf891474ca88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_intent_acc': 0.8665919303894043, 'test_slot_f1': 0.4552663564682007}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d68ddcaa49534c2496c0801b9ff6c225",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_intent_acc': 0.8656215071678162, 'test_slot_f1': 0.45187908411026}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f7d6ea7b80044beacd9a1e30ecc2c1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_intent_acc': 0.871220588684082, 'test_slot_f1': 0.4490077793598175}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fae93d9400e54100a40348eaa1e7c9c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_intent_acc': 0.8688340783119202, 'test_slot_f1': 0.4546431005001068}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68520cb921fe47b0941af4ff5b6a8b34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_intent_acc': 0.8533034920692444, 'test_slot_f1': 0.45157065987586975}\n",
      "--------------------------------------------------------------------------------\n",
      "acc: [0.8651, 0.0031] slotsF1 [0.4525, 0.0011]\n"
     ]
    }
   ],
   "source": [
    "# testing the model\n",
    "\n",
    "acc,slotF1 = [],[]\n",
    "\n",
    "test_files = [ './data/multiATIS/split/test/BG_Noise/0_75/test_EN_01.tsv',\n",
    "               './data/multiATIS/split/test/BG_Noise/0_75/test_EN_02.tsv',\n",
    "               './data/multiATIS/split/test/BG_Noise/0_75/test_EN_03.tsv',\n",
    "               './data/multiATIS/split/test/BG_Noise/0_75/test_EN_04.tsv',\n",
    "               './data/multiATIS/split/test/BG_Noise/0_75/test_EN_05.tsv'\n",
    "             ]\n",
    "#model = jointBert.load_from_checkpoint(\"./jointBert-epoch=17-val_loss=0.00.ckpt\",cfg=config)\n",
    "    \n",
    "for test_fn in test_files:\n",
    "    \n",
    "    dm = NLU_Dataset_pl(test_fn,test_fn, test_fn,config['mc']['tokenizer_name'],config['dc']['max_len'],64,1)\n",
    "    dm.setup() \n",
    "    test = dm.test_dataloader()\n",
    "    out = trainer.test(model=model ,test_dataloaders=test)\n",
    "    acc.append(out[0]['test_intent_acc'])\n",
    "    slotF1.append(out[0]['test_slot_f1'])\n",
    "    \n",
    "print('acc:',cal_mean_stderror(acc),'slotsF1',cal_mean_stderror(slotF1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
